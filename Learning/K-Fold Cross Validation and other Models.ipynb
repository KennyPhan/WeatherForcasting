{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d86353c",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation \n",
    "\n",
    "K-fold cross-validation is a technique for evaluating predictive models. The dataset is divided into k subsets or folds. The model is trained and evaluated k times, using a different fold as the validation set each time. Performance metrics from each fold are averaged to estimate the model’s generalization performance. This method aids in model assessment, selection, and hyperparameter tuning, providing a more reliable measure of a model’s effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419614ec",
   "metadata": {},
   "source": [
    "Example: https://www.kaggle.com/code/satishgunjal/tutorial-k-fold-cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657aadd6",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "A decision tree is a type of supervised machine learning used to categorize or make predictions based on how a previous set of questions were answered. \n",
    "\n",
    "|Decision Tree|Random Forest|\n",
    "|:---|:---|\n",
    "|A decision tree is a tree-like model of decisions along with possible outcomes in a diagram.|A classification algorithm consisting of many decision trees combined to get a more accurate result as compared to a single tree.|\n",
    "|There is always a scope for overfitting, caused due to the presence of variance.|Random forest algorithm avoids and prevents overfitting by using multiple trees.|\n",
    "|The results are not accurate.|This gives accurate and precise results.|\n",
    "|Decision trees require low computation, thus reducing time to implement and carrying low accuracy.|This consumes more computation. The process of generation and analyzing is time-consuming.| \n",
    "|It is easy to visualize. The only task is to fit the decision tree model.|This has complex visualization as it determines the pattern behind the data.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c94b0",
   "metadata": {},
   "source": [
    "Example:https://www.geeksforgeeks.org/python-decision-tree-regression-using-sklearn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e92259",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBoost is an optimized distributed gradient boosting library designed for efficient and scalable training of machine learning models. It is an ensemble learning method that combines the predictions of multiple weak models to produce a stronger prediction. XGBoost stands for “Extreme Gradient Boosting” and it has become one of the most popular and widely used machine learning algorithms due to its ability to handle large datasets and its ability to achieve state-of-the-art performance in many machine learning tasks such as classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14856e",
   "metadata": {},
   "source": [
    "Example: https://www.kaggle.com/code/dansbecker/xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb709f5",
   "metadata": {},
   "source": [
    "# LightGBM\n",
    "Light GBM is a gradient boosting framework that uses tree based learning algorithm. It differs from other tree based algorithm by growing grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e395e1a",
   "metadata": {},
   "source": [
    "Example: https://www.kaggle.com/code/josephchan524/housepricesregressor-using-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16bb221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
